"""

    AE Model

"""
from collections import Counter, OrderedDict

import torch
from sklearn.metrics import confusion_matrix
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
import numpy as np

from utilities.metrics_measure import mean_square_error, confusion_matrix_local


def tensor2array(tensor_v):
    return tensor_v.data.numpy()


def distance_measure(out_pred, x_test, loss_mode='mse'):
    # dist = []
    # for idx, v in enumerate(out_pred):
    #     tmp = 0.0
    #     for i in range(len(x_test[idx])):
    #         tmp += np.square(v.data.numpy()[i] - x_test[idx][i].data.numpy())
    #     dist.append(tmp)
    # dist = np.sum(np.square(np.asarray(out_pred)-np.asarray(x_test)),axis = 1)   # axis = 1, add by column
    x1 = np.asarray(out_pred)
    x2 = np.asarray(x_test)
    dist = mean_square_error(x1, x2, axis=1)

    return dist


class AE_Model(nn.Module):

    def __init__(self, in_dim=100, h_dim=20, Epoches=10):
        super(AE_Model, self).__init__()

        self.Epoches = Epoches
        self.batch_size = 32
        self.encoder = nn.Sequential(
            nn.Linear(in_dim, h_dim),
            nn.LeakyReLU(True),
            nn.Linear(h_dim, int(h_dim / 4)),
            nn.LeakyReLU(True)
        )

        self.decoder = nn.Sequential(
            nn.Linear(int(h_dim / 4), h_dim),
            nn.LeakyReLU(True),
            nn.Linear(h_dim, in_dim),
            # nn.Sigmoid()
        )

        self.criterion = nn.MSELoss()
        self.optim = torch.optim.Adam(AE_Model.parameters(self), lr=10e-3)

    def forward(self, x):
        latent_out = self.encoder(x)
        out = self.decoder(latent_out)

        return out

    def train(self, train_set, val_set):
        x_train, y_train = train_set

        dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(x_train))
        data_loader = DataLoader(dataset=dataset, batch_size=self.batch_size, shuffle=True)

        factor = 1  # thres = loss* factor
        self.res_dict = OrderedDict({'loss_train': [], 'loss_val': [],
                                     'cm_train': [], 'cm_val': [],
                                     'dist_val': []})  # cm: confusion matrix
        for epoch in range(self.Epoches):
            loss_train = 0.0
            for idx, (X_batch, _) in enumerate(data_loader):
                out = self.forward(X_batch)
                loss_batch = self.criterion(out, X_batch)

                self.optim.zero_grad()
                loss_batch.backward()
                self.optim.step()

                # if (idx + 1) % 100 == 0:
                #     print(f'Epoch {epoch+1}/{self.Epoches}, Loss={loss_batch.data[0]}')
                loss_train += loss_batch

            num_batch = idx + 1
            loss_train = tensor2array(loss_train).tolist() / num_batch
            self.res_dict['loss_train'].append(loss_train)  # average loss

            # evaluate on val set
            loss_val, cm_val, dists_val = self.evaluate(val_set, reconstr_thres=loss_train * factor)
            self.res_dict['loss_val'].append(tensor2array(loss_val).tolist())  # average loss
            self.res_dict['cm_val'].append(cm_val.tolist())  # cm
            # self.res_dict['dist_val'].append(dists_val)

            if (epoch + 1) % 10 == 0:
                print(f'Epoch {epoch+1}/{self.Epoches}, loss_train={loss_train}, loss_val={loss_val}')
                print(f'cm_val:{cm_val}')

        self.reconst_thres = loss_train * factor

        return self.res_dict, self.reconst_thres

    def evaluate(self, test_set, reconstr_thres=0.1):

        x_test, y_test = test_set
        with torch.no_grad():
            # test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(x_test))
            x_test = torch.Tensor(x_test)
            out_preds = self.forward(x_test)
            dists = distance_measure(out_preds, x_test, loss_mode='mse')
            loss_test = self.criterion(out_preds, x_test)
            print(
                f'loss_test({tensor2array(loss_test)}) == np.mean(dists)({np.mean(dists)}):{tensor2array(loss_test) == np.mean(dists)}')

        self.y_preds_label = []
        dists_dict = {'normal': [], 'malicious': []}
        for idx, (v, y) in enumerate(zip(dists, y_test)):
            if int(y) == 1:  # 1: normal, 0: attack
                dists_dict['normal'].append(v)
            else:
                dists_dict['malicious'].append(v)
            if v < reconstr_thres:
                self.y_preds_label.append(1)  # normal
            else:
                self.y_preds_label.append(0)  # attack

        cm = confusion_matrix(y_pred=self.y_preds_label, y_true=y_test)
        # print(f'cm:{cm}')
        cm = confusion_matrix_local(self.y_preds_label, y_test)
        # print(f'cm:{cm}')

        return loss_test, cm, dists_dict
