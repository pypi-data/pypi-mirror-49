from pprint import pprint
import pytest
import json
import en_core_web_sm
from role_pattern_nlp import RolePatternBuilder, RolePatternSet
from role_pattern_nlp.exceptions import FeaturesNotInFeatureDictError
import visualise_spacy_tree


nlp = en_core_web_sm.load()

text1 = 'We introduce efficient methods for fitting Boolean models to molecular data, successfully demonstrating their application to synthetic time courses generated by a number of established clock models, as well as experimental expression levels measured using luciferase imaging.'
doc1 = nlp(text1)

text2 = 'The amyloid-beta oligomer hypothesis was introduced in 1998.'
doc2 = nlp(text2)

docs = [doc1, doc2]


def idxs_to_tokens(doc, idxs):
    return [doc[idx] for idx in idxs]


test_cases = [
    {
        'doc': doc1,
        'match_examples': [
            {
                'slot1': idxs_to_tokens(doc1, [0]),  # [We]
                'slot2': idxs_to_tokens(doc1, [1]),  # [introduce]
                'slot3': idxs_to_tokens(doc1, [3]),  # [methods]
            },
            {
                'slot1': idxs_to_tokens(doc1, [13, 15]),  # [demonstrating, application]
                'slot2': idxs_to_tokens(doc1, [16, 19])  # [to, courses]
            },
            {
                'arg1': idxs_to_tokens(doc1, [19]),  # [courses]
                'pred': idxs_to_tokens(doc1, [20, 21]),  # [generated, by]
                'arg2': idxs_to_tokens(doc1, [27])  # [models]
            },
        ],
    },
    {
        'doc': doc2,
        'match_examples': [
            {
                'arg1': idxs_to_tokens(doc2, [5]),  # [hypothesis]
                'pred': idxs_to_tokens(doc2, [6]),  # [was]
                'arg2': idxs_to_tokens(doc2, [7]),  # [introduced]
            },
        ],
    },
]


feature_combs = [
    ['DEP', 'TAG', 'LOWER'],
    ['DEP', 'TAG'],
    ['DEP'],
]


def test_build_pattern_and_find_matches():
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_', 'LOWER': 'lower_'}
    for test_case in test_cases:
        doc = test_case['doc']
        match_examples = test_case['match_examples']
        role_pattern_builder = RolePatternBuilder(feature_dict)
        for features in feature_combs:
            for match_example in match_examples:
                role_pattern = role_pattern_builder.build(match_example, features=features, validate_pattern=True)
                matches = role_pattern.match(doc)
                assert match_example in matches


def test_refine_pattern():
    match_example = {
        # 'arg1': idxs_to_tokens(doc1, [3]),  # [methods]
        'prep': idxs_to_tokens(doc1, [4]),  # [for]
        'arg2': idxs_to_tokens(doc1, [7]),  # [models]
    }
    neg_examples = [{
        # 'arg1': idxs_to_tokens(doc1, [3]),  # [methods]
        'prep': idxs_to_tokens(doc1, [8]),  # [to]
        'arg2': idxs_to_tokens(doc1, [10]),  # [data]
    }]
    # pprint(match_example)
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_', 'LOWER': 'lower_'}
    role_pattern_builder = RolePatternBuilder(feature_dict)
    pattern = role_pattern_builder.build(
        match_example, features=['DEP']
    )
    matches = pattern.match(doc1)
    assert match_example in matches
    assert neg_examples[0] in matches
    # pattern = role_pattern_builder.refine(doc1, pattern, match_example, neg_examples)
    refined_role_pattern_variants = role_pattern_builder.refine(pattern, match_example, neg_examples)
    for role_pattern_variant in refined_role_pattern_variants:
        matches = role_pattern_variant.match(doc1)
        assert match_example in matches
        assert neg_examples[0] not in matches


def test_validate_features():
    match_examples = [
        {
            'slot1': idxs_to_tokens(doc1, [0, 1, 3])  # [We, introduce, methods]
        },
    ]
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_'}
    role_pattern_builder = RolePatternBuilder(feature_dict)
    features = ['DEP', 'TAG', 'LOWER']
    for match_example in match_examples:
        with pytest.raises(FeaturesNotInFeatureDictError):
            role_pattern_builder.build(match_example, features=features)


def test_visualise_pattern():
    for i, doc in enumerate(docs):
        png = visualise_spacy_tree.create_png(doc)
        filepath = 'examples/sentence_vis/sentence_{}.png'.format(i)
        with open(filepath, 'wb') as f:
            f.write(png)
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_', 'LOWER': 'lower_'}
    for test_i, test_case in enumerate(test_cases):
        match_examples = test_case['match_examples']
        role_pattern_builder = RolePatternBuilder(feature_dict)
        for features_i, features in enumerate(feature_combs):
            for match_example in match_examples:
                role_pattern = role_pattern_builder.build(match_example, features=features)
                filepath = 'examples/spacy_dep_patterns/pattern_{}_{}.json'.format(test_i, features_i)
                with open(filepath, 'w') as f:
                    json.dump(role_pattern.spacy_dep_pattern, f, indent=2)
                pydot, legend = role_pattern.to_pydot(legend=True)
                png = pydot.create_png()
                filename = 'examples/pattern_vis/pattern_{0}_{1}.png'.format(test_i, features_i)
                with open(filename, 'wb') as f:
                    f.write(png)


def test_visualise_pattern_legend():
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_', 'LOWER': 'lower_'}
    role_pattern_builder = RolePatternBuilder(feature_dict)
    test_case = test_cases[1]
    match_example = test_case['match_examples'][0]
    role_pattern = role_pattern_builder.build(match_example)
    pydot, legend = role_pattern.to_pydot(legend=True)
    png = legend.create_png()
    filename = 'examples/pattern_vis/pattern_1_0_legend.png'
    with open(filename, 'wb') as f:
        f.write(png)


def test_visualise_pattern_match():
    feature_dict = {'DEP': 'dep_', 'TAG': 'tag_', 'LOWER': 'lower_'}
    for test_i, test_case in enumerate(test_cases):
        doc = test_case['doc']
        match_examples = test_case['match_examples']
        role_pattern_builder = RolePatternBuilder(feature_dict)
        for features_i, features in enumerate(feature_combs):
            for match_example in match_examples:
                role_pattern = role_pattern_builder.build(match_example, features=features)
                matches = role_pattern.match(doc)
                for match in matches:
                    graph, legend = match.to_pydot(legend=True)
                    png = graph.create_png()
                    filename = 'examples/match_vis/match_{0}_{1}.png'.format(test_i, features_i)
                    with open(filename, 'wb') as f:
                        f.write(png)
    png = legend.create_png()
    filename = 'examples/match_vis/match_{0}_{1}_legend.png'.format(test_i, features_i)
    with open(filename, 'wb') as f:
        f.write(png)


# def test_role_pattern_set():
#     match_examples = [
#         {
#             'slot1': idxs_to_tokens(doc1, [0, 1, 3]),  # [We, introduce, methods]
#         },
#         {
#             'slot1': idxs_to_tokens(doc1, [13, 15]),  # [demonstrating, application]
#             'slot2': idxs_to_tokens(doc1, [16, 19])  # [to, courses]
#         },
#         {
#             'arg1': idxs_to_tokens(doc1, [19]),  # [courses]
#             'pred': idxs_to_tokens(doc1, [20, 21]),  # [generated, by]
#             'arg2': idxs_to_tokens(doc1, [27])  # [models]
#         },
#     ]
#     pattern_set = RolePatternSet()
#     role_pattern_builder = RolePatternBuilder()
#     pattern_count = 0
#     for match_example in match_examples:
#         role_pattern = role_pattern_builder.build(doc1, match_example)
#         role_pattern.name = 'pattern_{}'.format(pattern_count)
#         pattern_set.add(role_pattern)
#         matches = role_pattern.match(doc1)
#         pattern_count += 1
#     matches = pattern_set.match(doc1)
#     pprint(matches)
#     assert all([m in matches for m in match_examples])