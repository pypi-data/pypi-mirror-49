"""
    extract tcp flows (biflow (session) or flow) from .pcap by Scapy


    shortcomings:
        (Splitcap (https://www.netresec.com/?page=SplitCap) also has the same issues. However, it is very fast than this code.)

        1) does not perform any proper TCP session reassembly. This means that TCP retransmissions
              and overlapping segments will cause the same data to be written twice.
              Out-of-order TCP packets will also cause the application layer data to be stored in an out of order sequence.

              "Applications that can do proper TCP session reassembly are NetworkMiner and Wireshark".

        2) does not make sure the session begin with handshake.


    -------------------------------------------------------------------------------------------------------------------
    tshark:
    https://www.activecountermeasures.com/blog-tshark-examples-for-extracting-ip-fields/

    You can use tcpdump itself with the -C, -r and -w options
    tcpdump -r old_file -w new_files -C 10
    The "-C" option specifies the size of the file to split into. Eg: In the above case new files size will be 10 million bytes each.

    Check the information of pcap file.

    capinfos output_00001_20170703081536.pcap


    editcap -F libpcap -A "2017-07-07 10:05:00" -B "2017-07-07 10:20:00" Friday-WorkingHours.pcap output.pcap


    tshark -r output_time_10-05-00_10-20-00.pcap -w output_filter_ips.pcap ip.addr==205.174.165.73

    tshark -r Friday-WorkingHours.pcap -w output_filter_ips.pcap ip.addr==205.174.165.73

    tshark -r interesting-host.pcap -T fields -e ip.src -e ip.dst ip.dst==192.168.1.10 | head


"""
from collections import OrderedDict

from scapy.all import PcapReader, wrpcap
import os

from scapy.layers.inet import IP

PT_NUM = 10000  # print interval


def extract_meta_info_from_packet(raw_pkt, mode='RAW', idx=0):
    five_tuple_lst = []
    time = ''
    payload = b''
    pkt = raw_pkt
    while pkt.name.upper() != "RAW":
        key = pkt.name.upper()
        if key == 'NOPAYLOAD':
            break
        # if storage_mode.upper() == "L7":  # TCP/UDP payload
        #     five_tuple_lst, payload = extract_meta_info_from_packet(pkt, mode= storage_mode.upper(), idx=pcap_stats['pkts_n'])
        # if storage_mode.upper() == "L4":  # TCP/UDP Header + payload
        #     five_tuple_lst, payload = extract_meta_info_from_packet(pkt, mode=storage_mode.upper(), idx=pcap_stats['pkts_n'])
        #     payload = pkt.payload
        # else:  # storage_mode.upper() == "RAW":  # save as .pcap, default
        #     five_tuple_lst, payload = extract_meta_info_from_packet(pkt, mode = storage_mode.upper(), idx=pcap_stats['pkts_n'])
        #     payload = pkt  # save all information of each packet.

        # # print(key)
        # if key == "ETHERNET":  # Ethernet
        #     time = pkt.time  # Ethernet time
        #     pkt = pkt.payload
        #     #  print('other protrocols, please analyze them manually.')
        #     continue
        if key == "IP" or key == "IPV6":
            five_tuple_lst = [pkt.src, pkt.dst]
            if mode.upper() == "L3":  # IP Header + payload
                payload = pkt.original  # only bytes
                return five_tuple_lst, payload
        if key == "TCP" or key == "UDP":
            five_tuple_lst.extend([str(pkt.sport), str(pkt.dport), key])
            if mode.upper() == "L4":  # TCP/UDP Header + payload
                payload = pkt.original  # only bytes
                return five_tuple_lst, payload
            if mode.upper() == "L7":  # TCP/UDP  payload
                payload = pkt.payload.original  # only bytes
                return five_tuple_lst, payload
        pkt = pkt.payload

    if payload == b'':
        if raw_pkt.payload.name.upper() != 'NOPAYLOAD':
            print(
                f'idx={idx}, other protrocols={raw_pkt.payload.name}, {five_tuple_lst}, {time}, paylaod={payload}, please analyze them manually.')

    return five_tuple_lst, payload

    # def get_prtls_from_pkt(pkt):
    #     # prtls_dict = OrderedDict({'IP':'','TCP':'','UDP':'','Other':''})
    #     prtls_dict = OrderedDict()
    #     five_tuple_lst=[]
    #     while pkt.name != "Raw":
    #         key=pkt.name.upper()
    #         # print(key)
    #         if key == "IP":
    #             five_tuple_lst = [pkt.src, pkt.dst]
    #         if key == "TCP" or key == "UDP":
    #             five_tuple_lst.extend([str(pkt.sport), str(pkt.dport)])
    #         else:
    #             pass
    #             #  print('other protrocols, please analyze them manually.')
    #         if key not in prtls_dict.keys():
    #            prtls_dict[key] = pkt
    #         pkt = pkt.payload
    #
    #     return prtls_dict
    #
    # prtls_dict = get_prtls_from_pkt(pkt)

    # five_tuple_lst = []
    # if "IP" in prtls_dict.keys():
    #     ip_pkt = prtls_dict["IP"]
    #     five_tuple_lst = [ip_pkt.src, ip_pkt.dst]
    #     payload = ip_pkt.payload
    # if "TCP" in prtls_dict.keys():
    #     tcp_pkt = prtls_dict["TCP"]
    #     # ports = str(payload.sport) +":"+ str(payload.dport)
    #     five_tuple_lst.extend([str(tcp_pkt.sport), str(tcp_pkt.dport)])
    #     payload = tcp_pkt.payload
    #     prtl = "TCP"
    # elif "UDP" in prtls_dict.keys():
    #     udp_pkt = prtls_dict["UDP"]
    #     five_tuple_lst.extend([str(udp_pkt.sport), str(udp_pkt.dport)])
    #     payload = udp_pkt.payload
    #     prtl = "UDP"
    # else:
    #     print('other protrocols, please analyze them manually.')
    #
    # five_tuple_lst.append(prtl)

    # return five_tuple_lst, payload


def filter_ips(pkt, filter_ips_list=[]):
    if IP(pkt).src in filter_ips_list or IP(pkt).dst in filter_ips_list:
        return -1
    else:
        return pkt


def extract_flows_from_pcap(in_file='.pcap', remain_ips=[], biflow=True, pkts_num_in_flow=-1, storage_mode="RAW"):
    """

    :param in_file:
    :param biflow: Ture, represents store sessions.
    :param pkts_num_in_flow: -1 (negative) means save all packets of each flow. Otherwise, only extract the first num (such as 300) packets of each flow.
    :return:
    """
    print(f'in_file={in_file}')
    sess_order_dict = OrderedDict()
    pcap_stats = {'pkts_n': 0, 'sessions_n': 0, 'tcp_n': 0, 'udp_n': 0, 'others_n': 0}

    pcap_reader = PcapReader(in_file)
    pkt = pcap_reader.read_packet()
    while pkt:
        pcap_stats['pkts_n'] += 1
        five_tuple_lst, payload = extract_meta_info_from_packet(pkt, mode=storage_mode.upper(),
                                                                idx=pcap_stats['pkts_n'])

        if "TCP" in five_tuple_lst:
            pcap_stats['tcp_n'] += 1
        elif "UDP" in five_tuple_lst:
            pcap_stats['udp_n'] += 1
        else:  # # does not have five_tuple, such ARP protocol.
            pcap_stats['others_n'] += 1
            pkt = pcap_reader.read_packet()
            continue

        if len(five_tuple_lst) < 5:
            print(f'five_tuple_lst:{five_tuple_lst}, payload:{payload}')
            pkt = pcap_reader.read_packet()
            continue

        if len(remain_ips) > 0:  # only keep ips in remain_ips.
            if five_tuple_lst[0] not in remain_ips or five_tuple_lst[1] not in remain_ips:
                pcap_stats['others_n'] += 1
                pkt = pcap_reader.read_packet()
                continue

        five_tuple_1 = five_tuple_lst[0] + ":" + five_tuple_lst[2] + "-" + five_tuple_lst[1] + ":" + five_tuple_lst[
            3] + "-" + five_tuple_lst[-1]
        if biflow:  # session
            five_tuple_2 = five_tuple_lst[1] + ":" + five_tuple_lst[3] + "-" + five_tuple_lst[0] + ":" + five_tuple_lst[
                2] + "-" + five_tuple_lst[-1]
        else:
            five_tuple_2 = five_tuple_1  # uniflow

        if pcap_stats['pkts_n'] % PT_NUM == 0:
            n_tmp = pcap_stats['pkts_n']
            print(
                f'pcap_stats[\'pkts_n\']={n_tmp}, biflow={biflow}, five_tuple_1={five_tuple_1}, five_tuple_2={five_tuple_2}')

        if five_tuple_1 not in sess_order_dict.keys() and five_tuple_2 not in sess_order_dict.keys():
            sess_order_dict[five_tuple_1] = [payload]
        else:
            if five_tuple_1 not in sess_order_dict.keys():
                five_tuple_1 = five_tuple_2  # only save five_tuple_1, if biflow = True.
            if pkts_num_in_flow < 0:
                # print(f'{five_tuple_1}')
                sess_order_dict[five_tuple_1].append(payload)
            else:
                if len(sess_order_dict[
                           five_tuple_1]) < pkts_num_in_flow:  # only store the first num (such as 300) packets
                    sess_order_dict[five_tuple_1].append(payload)

        pkt = pcap_reader.read_packet()

    pcap_stats['sessions_n'] = len(sess_order_dict)
    print(f'pcap_stats:{pcap_stats}')

    return sess_order_dict, pcap_stats


def write_sessions_to_files(sess_order_dict, out_dir, storage_mode="RAW"):
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    def write_session_to_file(out_file, value, storage_mode):
        if storage_mode == "L7" or storage_mode == "L4" or storage_mode == "L3":
            with open(out_file, 'wb') as out_hdr:
                str = b''
                for v in value:  #
                    str += v
                out_hdr.write(str)
        else:  # default
            str = b''
            for v in value:  #
                str += v.original  #
            wrpcap(out_file, value)  # be careful for "wrpcap", which cannot save original bytes directly.

        return len(str)

    for idx, (key, value) in enumerate(sess_order_dict.items()):
        if storage_mode.upper() == "L7" or storage_mode.upper() == "L4" or storage_mode.upper() == "L3":
            out_file = os.path.join(out_dir, key + '.bin')
        else:  # default
            out_file = os.path.join(out_dir, key + '.pcap')
        data_len = write_session_to_file(out_file, value, storage_mode)
        if (idx) % PT_NUM == 0:
            print(f'idx={idx}, out_file={out_file}, bytes_len={data_len}')


def main():
    in_files_dict = {
        'unb_norm': '../data/UNB-IDS2017/Normal_traffic/Monday-WorkingHours_output_00001_20170703081536.pcap',
        'unb_malic': '../data/UNB-IDS2017/Malware_traffic/Friday-WorkingHours_output_time_10-05-00_10-20-00.pcap',
        'ctu_malic': '../data/CTU_malware_traffic/botnet-capture-20110810-neris-30000pkts.pcap',
        'skype_norm': '../data/Skype.pcap'

        }
    case = "U_norm-U_malic:L7"  # case[1]= UNB normal, case[3]= UNB malicious, case[5]=7 (L7)
    # case = "Skype_norm-U_malic:L7"
    # filter_ips_from_pcap(in_file)
    if case == "U_norm-U_malic:L7":  # only TCP/UDP payload
        in_file_lst = [in_files_dict['unb_malic'], in_files_dict['unb_malic']]
        storage_mode = "L7"
    elif case == "U_norm-U_malic:L4":  # TCP/UDP Header + payload, i.e., IP.payload
        in_file_lst = [in_files_dict['unb_norm'], in_files_dict['unb_malic']]
        storage_mode = "L4"
    elif case == "Skype_norm-U_malic:L7":  # TCP/UDP Header + payload, i.e., IP.payload
        in_file_lst = [in_files_dict['skype_norm'], in_files_dict['unb_malic']]
        storage_mode = "L7"
    else:
        print('input right case.')
        return -1

    for in_file in in_file_lst:
        if 'UNB' in in_file.upper() and 'MAL' in in_file.upper():
            "refer to: https://www.unb.ca/cic/datasets/ids-2017.html"
            remain_ips = ['205.174.165.73', '192.168.10.15', '192.168.10.9', '192.168.10.14', '192.168.10.5',
                          '192.168.10.8']
        else:
            remain_ips = []  # remain all ips.
        print(f'remain_ips={remain_ips}, if [], remain all ips.')
        sess_order_dict, pcap_stats = extract_flows_from_pcap(in_file, biflow=True, pkts_num_in_flow=100,
                                                              storage_mode=storage_mode, remain_ips=remain_ips)

        # out_dir = os.path.join(os.path.dirname(in_file), os.path.splitext(in_file))
        out_dir = os.path.splitext(in_file)[0]
        write_sessions_to_files(sess_order_dict, out_dir, storage_mode=storage_mode)


if __name__ == '__main__':
    main()
