"""Contains methods for compiling an EBNF grammar into a Parser."""

from collections import namedtuple
from datetime import datetime

from .exception import CompilerError
from .operator import Operator, OperatorNode, OptreeNode, infix_to_optree
from .parser import Parser, TokenType
from .util import esc_split


Directive = namedtuple("Directive", ["name", "args"])

# Abstract Syntax Tree Nodes
Rule = namedtuple("Rule", ["name", "expression", "position", "consumed"])
Identifier = namedtuple("Identifier", ["value"])
Terminal = namedtuple("Terminal", ["value"])
OptionGroup = namedtuple("OptionGroup", ["expression"])
RepetitionGroup = namedtuple("RepetitionGroup", ["expression"])
GroupingGroup = namedtuple("GroupingGroup", ["expression"])
SpecialHandling = namedtuple("SpecialHandling", ["value"])
Number = namedtuple("Number", ["value"])

OP_ALTERNATE = Operator("|", 2)
OP_WS_CONCAT = Operator(".", 3)
OP_CONCAT = Operator(",", 4)
OP_EXCLUDE = Operator("-", 5)
OP_MULTIPLY = Operator("*", 6)
OP_REPEAT = Operator("+", 7, cardinality=1)
OPERATORS = [OP_ALTERNATE, OP_WS_CONCAT, OP_CONCAT, OP_EXCLUDE, OP_MULTIPLY, OP_REPEAT]
OPERATOR_INDEX = {o.symbol: o for o in OPERATORS}

PB_SPECIAL_HANDLING = {"get_ascii_letter", "get_ascii_lowercase", "get_ascii_uppercase",
                       "get_digit", "get_hexdigit", "get_octdigit", "get_printable",
                       "get_punctuation", "get_whitespace"}

_TERMINAL_REPLACEMENTS = (("\\", "\\\\"),
                          ("\\\\n", "\\n"))


class Compiler(object):
  """This class takes EBNF source code and generates a parse tree, and abstract syntax tree, and
  python source code output.
  """
  def __init__(self, source, indent="  ", *, use_terminal_shorthand=True):
    """Initialize the Compiler instance."""
    self.input_source = source
    self.indent = indent
    self.use_terminal_shorthand = use_terminal_shorthand
    self.parser = None
    self._grammar = None
    self._rules = None
    self._comments = None
    self._directives = None
    self._output_source = None

  @property
  def grammar(self):
    """The parse tree generated by the source."""
    if self._grammar is None:
      self.parser = Parser()
      grammar = self.parser.parse(self.input_source)
      self._grammar = grammar.trimmed().flattened().flattened(self._flatten)
    return self._grammar

  @property
  def rules(self):
    """The AST rules."""
    if self._rules is None:
      self._rules = []
      for child in self.grammar.children:
        if child.is_type(TokenType.rule):
          name, expression = child.children
          self._rules.append(Rule(name.value, self._expression_to_asn(expression), name.position, child.consumed))
    return self._rules

  @property
  def comments(self):
    """The AST comments."""
    if self._comments is None:
      self._comments = [c for c in self.grammar.children if c.is_type(TokenType.comment)]
    return self._comments

  @property
  def directives(self):
    """The diretives parsed from the comments."""
    if self._directives is None:
      self._directives = []
      for comment in self.comments:
        self._directives.extend(self.directives_from_comment(comment))
    return self._directives

  @property
  def output_source(self):
    """The python source of the parser generated from the input source."""
    if self._output_source is None:
      self._output_source = self._compile()
    return self._output_source

  # Source code generators
  def _compile(self):
    """Returns the python source code for the generated parser."""
    fmt = """\"\"\"This parser was generated by pyebnf on {date}.\"\"\"
    from enum import Enum

    from pyebnf import parser_base as PB
    from pyebnf.primitive import alternation, concatenation, exclusion, one_or_more
    from pyebnf.primitive import option, repeated, repetition, terminal, zero_or_more
    {imports}

    {token_type_enum}


    {class_definition}
    """

    fmt = self._clean_fmt(fmt)

    return fmt.format(date=datetime.utcnow().isoformat(),
                      imports=self._get_imports(),
                      token_type_enum=self._get_token_type_enum(),
                      class_definition=self._get_class_definition())

  def _get_imports(self):
    """Reads the directives and generates source code for custom imports."""
    import_directives = [d for d in self.directives if d.name == "import"]
    if import_directives:
      return "\n" + "\n".join(d.args["value"] for d in import_directives)
    else:
      return ""

  def _get_token_type_enum(self):
    """Builds the python source code for the Parser TokenType enum."""
    fmt = "class TokenType(Enum):\n" \
          "{indent}\"\"\"The token types for parse nodes generated by the Parser.\"\"\"\n" \
          "{indent}" + \
          "\n{indent}".join("{1} = {0}".format(num + 1, r.name) for num, r in enumerate(self.rules))
    return fmt.format(indent=self.indent)

  def _get_class_definition(self):
    """Builds the class definition of the parser."""
    fmt = """class Parser({parser_base}):
             {indent}\"\"\"This class contains methods for reading source code and generating a parse tree.\"\"\"
             {indent}entry_point = "{entry_point}"

             {rule_definitions}
             """
    fmt = self._clean_fmt(fmt)
    return fmt.format(parser_base=self._get_parser_base(),
                      indent=self.indent,
                      entry_point=self._get_entry_point(),
                      rule_definitions="\n".join(self._get_rule_definitions()))

  def _get_parser_base(self):
    """Gets the base class name for the parser."""
    pb = self._find_directive("parser_base")
    if pb:
      return pb.args["value"]
    else:
      return "PB.ParserBase"

  def _get_entry_point(self):
    """Gets the entry_point value for the parser."""
    ep = self._find_directive("entry_point")
    if ep:
      return ep.args["value"]
    else:
      return self.rules[0].name

  def _get_rule_definitions(self):
    """Generates the source code for each of the rules."""
    for rule in self.rules:
      yield self._get_rule_definition(rule)

  def _get_rule_definition(self, rule):
    """Generates the source code for a rule."""
    fmt = """def {rule_fxn_name}(self, text):
             {indent}\"\"\"{rule_source}\"\"\"
             {indent}self._attempting(text)
             {indent}return {rule_definition}(text){transform}
          """
    fmt = self._clean_fmt(fmt)
    source = self._indent(self._ast_to_code(rule.expression), skip_first_line=True)

    # All the primitives will accept a string x in place of terminal(x). This is terminal shorthand.
    # However, if a rule is only a wrapper around a single terminal, we have to actually make a
    # terminal call. This handles that situation.
    if self.use_terminal_shorthand and len(source) == 1 and source[0].startswith(("'", '"')):
      source = ["terminal({})".format(source[0])]

    rule_source = fmt.format(rule_fxn_name=self._get_rule_fxn_name(rule.name),
                             indent=self.indent,
                             rule_source=self._get_rule_source(rule),
                             rule_definition="\n".join(source),
                             transform=self._get_rule_transform(rule))
    return self._indent(rule_source, 1)

  def _get_rule_fxn_name(self, name):
    """Converts a rule name to a function name."""
    return name

  def _get_rule_source(self, rule):
    """Gets the variable part of the source code for a rule."""
    p = len(self.input_source) + rule.position
    source = self.input_source[p:p + rule.consumed].rstrip()
    return self._indent(source, depth=self.indent + "   ", skip_first_line=True)

  def _get_rule_transform(self, rule):
    """The return value for each rule can be either retyped, compressed or left alone. This method
    determines that and returns the source code text for accomplishing it.
    """
    rd = self._find_directive(lambda d: d.name == "rule" and d.args.get("name") == rule.name)

    if rd:
      args = rd.args
    else:
      args = {}

    transform = args.get("transform", "retype")

    if transform == "retype":
      new_name = args.get("to_type", "TokenType.{0}".format(rule.name))
      return ".retyped({0})".format(new_name)
    elif transform == "compress":
      new_name = args.get("to_type", "TokenType.{0}".format(rule.name))
      if new_name == "identity":
        return ".compressed()"
      else:
        return ".compressed({0})".format(new_name)
    elif transform == "identity":
      return ""

  # Parse Tree -> Abstract Syntax Tree
  def _expression_to_asn(self, expression):
    """Convert an expression to an Abstract Syntax Tree Node."""
    new_children = [self._node_to_asn(c) for c in expression.children]
    return self._remove_grouping_groups(infix_to_optree(new_children))

  def _node_to_asn(self, node):
    """Convert a parse tree node into an absract syntax tree node."""
    if node.is_type(TokenType.identifier):
      return Identifier(node.svalue)

    elif node.is_type(TokenType.terminal):
      return Terminal(node.svalue)

    elif node.is_type(TokenType.option_group):
      expr = node.children[0]
      return OptionGroup(self._expression_to_asn(expr))

    elif node.is_type(TokenType.repetition_group):
      expr = node.children[0]
      return RepetitionGroup(self._expression_to_asn(expr))

    elif node.is_type(TokenType.grouping_group):
      expr = node.children[0]
      return GroupingGroup(self._expression_to_asn(expr))

    elif node.is_type(TokenType.special_handling):
      ident = node.children[0]
      return SpecialHandling(ident)

    elif node.is_type(TokenType.number):
      return Number(node.svalue)

    elif node.is_type((TokenType.operator, TokenType.op_mult, TokenType.op_add)):
      return OperatorNode(OPERATOR_INDEX[node.svalue], node.position)

    else:
      raise Exception("Unhandled parse tree node: {0}".format(node))

  # Tree mutators
  def _hoist_operands(self, operands, pred):
    """Flattens a list of optree operands based on a pred.

    This is used to convert concatenation([x, concatenation[y, ...]]) (or alternation) to
    concatenation([x, y, ...]).
    """
    hopper = list(operands)
    new_operands = []
    while hopper:
      target = hopper.pop(0)
      if pred(target):
        hopper = list(target.operands) + hopper
      else:
        new_operands.append(target)
    return new_operands

  def _remove_grouping_groups(self, optree):
    """Grouping groups are implied by optrees, this function hoists grouping group expressions up
    to their parent node.
    """
    new_operands = []
    for operand in optree.operands:
      if isinstance(operand, OptreeNode):
        new_operands.append(self._remove_grouping_groups(operand))
      elif isinstance(operand, GroupingGroup):
        new_operands.append(operand.expression)
      else:
        new_operands.append(operand)

    return OptreeNode(optree.opnode, new_operands)

  # AST to Python code
  def _ast_to_code(self, node, **kwargs):
    """Convert an abstract syntax tree to python source code."""
    if isinstance(node, OptreeNode):
      return self._ast_optree_node_to_code(node, **kwargs)
    elif isinstance(node, Identifier):
      return self._ast_identifier_to_code(node, **kwargs)
    elif isinstance(node, Terminal):
      return self._ast_terminal_to_code(node, **kwargs)
    elif isinstance(node, OptionGroup):
      return self._ast_option_group_to_code(node, **kwargs)
    elif isinstance(node, RepetitionGroup):
      return self._ast_repetition_group_to_code(node, **kwargs)
    elif isinstance(node, SpecialHandling):
      return self._ast_special_handling_to_code(node, **kwargs)
    elif isinstance(node, Number):
      return self._ast_number_to_code(node, **kwargs)
    else:
      raise Exception("Unhandled ast node: {0}".format(node))

  def _ast_optree_node_to_code(self, node, **kwargs):
    """Convert an abstract syntax operator tree to python source code."""
    opnode = node.opnode
    if opnode is None:
      return self._ast_to_code(node.operands[0])
    else:
      operator = opnode.operator
      if operator is OP_ALTERNATE:
        return self._ast_op_alternate_to_code(node, **kwargs)
      elif operator is OP_WS_CONCAT:
        kwargs["ignore_whitespace"] = False
        return self._ast_op_concat_to_code(node, **kwargs)
      elif operator is OP_CONCAT:
        kwargs["ignore_whitespace"] = True
        return self._ast_op_concat_to_code(node, **kwargs)
      elif operator is OP_EXCLUDE:
        return self._ast_op_exclude_to_code(node, **kwargs)
      elif operator is OP_MULTIPLY:
        return self._ast_op_multiply_to_code(node, **kwargs)
      elif operator is OP_REPEAT:
        return self._ast_op_repeat_to_code(node, **kwargs)
      else:
        raise Exception("Unhandled optree node: {0}".format(node))

  def _ast_identifier_to_code(self, identifier, **kwargs):
    """Convert an AST identifier to python source code."""
    return ["self.{}".format(self._get_rule_fxn_name(identifier.value))]

  def _ast_terminal_to_code(self, terminal, **kwargs):
    """Convert an AST terminal to python source code."""
    value = _replace(terminal.value)
    if self.use_terminal_shorthand:
      return [value]
    else:
      return ["terminal({})".format(value)]

  def _ast_option_group_to_code(self, option_group, **kwargs):
    """Convert an AST option group to python source code."""
    lines = ["option("]
    lines.extend(self._indent(self._ast_to_code(option_group.expression)))
    lines.append(")")
    return lines

  def _ast_repetition_group_to_code(self, repetition_group, ignore_whitespace=False, **kwargs):
    """Convert an AST repetition group to python source code."""
    lines = ["zero_or_more("]
    lines.extend(self._indent(self._ast_to_code(repetition_group.expression)))
    lines[-1] += ","
    lines.append(self._indent("ignore_whitespace={}".format(bool(ignore_whitespace))))
    lines.append(")")
    return lines

  def _ast_special_handling_to_code(self, special_handling, **kwargs):
    """Convert an AST sepcial handling to python source code."""
    ident = special_handling.value.svalue
    if ident in PB_SPECIAL_HANDLING:
      return ["PB.{0}".format(ident)]
    else:
      return ["self.{0}".format(ident)]

  def _ast_op_alternate_to_code(self, opr, **kwargs):
    """Convert an AST alternate op to python source code."""
    hoist_target = OP_ALTERNATE
    operands = self._hoist_operands(opr.operands, lambda t: isinstance(t, OptreeNode) and t.opnode.operator is hoist_target)

    lines = ["alternation(["]
    for op in operands:
      lines.extend(self._indent(self._ast_to_code(op)))
      lines[-1] += ","
    lines.append("])")
    return lines

  def _ast_op_concat_to_code(self, opr, *, ignore_whitespace, **kwargs):
    """Convert an AST concatenate op to python source code."""
    hoist_target = OP_CONCAT if ignore_whitespace else OP_WS_CONCAT
    operands = self._hoist_operands(opr.operands, lambda t: isinstance(t, OptreeNode) and t.opnode.operator is hoist_target)

    lines = ["concatenation(["]
    for op in operands:
      lines.extend(self._indent(self._ast_to_code(op, ignore_whitespace=ignore_whitespace)))
      lines[-1] += ","
    lines.append("], ignore_whitespace={})".format(bool(ignore_whitespace)))
    return lines

  def _ast_op_exclude_to_code(self, opr, **kwargs):
    """Convert an AST exclude op to python source code."""
    opl, opr = opr.operands

    lines = ["exclusion("]
    lines.extend(self._indent(self._ast_to_code(opl)))
    lines[-1] += ","
    lines.extend(self._indent(self._ast_to_code(opr)))
    lines.append(")")
    return lines

  def _ast_op_multiply_to_code(self, opr, ignore_whitespace=False, **kwargs):
    """Convert an AST multiply op to python source code."""
    opl, opr = opr.operands

    if isinstance(opl, Number):
      times = opl.value
      subject = self._ast_to_code(opr)
    else:
      times = opr.value
      subject = self._ast_to_code(opl)

    lines = ["repeated("]
    lines.extend(self._indent(subject))
    lines[-1] += ","
    lines.append("{0}times={1},".format(self.indent, times))
    lines.append("{0}ignore_whitespace={1}".format(self.indent, bool(ignore_whitespace)))
    lines.append(")")
    return lines

  def _ast_op_repeat_to_code(self, opr, ignore_whitespace=False, **kwargs):
    """Convert an AST repeat op to python source code."""
    lines = ["one_or_more("]
    lines.extend(self._indent(self._ast_to_code(opr.operands[0])))
    lines[-1] += ","
    lines.append(self._indent("ignore_whitespace={}".format(bool(ignore_whitespace))))
    lines.append(")")
    return lines

  # Text formatting
  def _indent(self, text, depth=1, *, skip_first_line=False, suffix=""):
    """Indent text by depth * self.indent.

    Text can be either a string, or a list of strings. If it is a string, it will be split on
    newline to a list of strings.

    if skip_first_line is true, the first line will not be indented like the others.
    """
    as_list = isinstance(text, list)

    if as_list:
      lines = text
    else:
      lines = text.split("\n")
    new_lines = []

    if isinstance(depth, int):
      spacing = self.indent * depth
    else:
      spacing = depth

    for i, line in enumerate(lines):
      if skip_first_line and i == 0:
        new_lines.append("{0}{1}".format(line, suffix))
      else:
        new_lines.append("{0}{1}{2}".format(spacing, line, suffix))

    if as_list:
      return new_lines
    else:
      return "\n".join(new_lines)

  # Directive utils
  def _find_directive(self, name):
    """Returns the first directive with a certain name or that passes a predicate."""
    dx = self._find_directives(name)
    if dx:
      return dx[0]
    else:
      return None

  def _find_directives(self, pred):
    """Finds all directives with a certain name, or that passes a predicate."""
    if isinstance(pred, str):
      return [d for d in self.directives if d.name == pred]
    else:
      return [d for d in self.directives if pred(d)]

  @staticmethod
  def _flatten(child, parent):
    """Custom flattening method for the parse tree."""
    return parent.is_type(TokenType.expression) and child.node_type == parent.node_type

  @staticmethod
  def _clean_fmt(fmt):
    """This takes a source code format string and strips off the leading spaces. This allows us to
    indent triple strings, but have the output not have the indents.
    """
    return "\n".join(l.strip() for l in fmt.split("\n"))

  @classmethod
  def directives_from_comment(cls, comment):
    """A directive is a line in a comment that begins with '!'."""
    comment_contents = comment.value[2:-2].strip()
    comment_lines = (l.strip() for l in comment_contents.split("\n"))
    directives = (l[1:].strip() for l in comment_lines if l.startswith("!"))

    for directive_def in directives:
      yield cls.parse_directive_def(directive_def)

  @classmethod
  def parse_directive_def(cls, directive_def):
    """Turns a directive definition string into a directive object."""
    name, *kwargs = esc_split(directive_def, ignore_empty=True)
    return Directive(name, {key: value for key, value in (esc_split(arg, "=") for arg in kwargs)})


def _replace(text, replacements=_TERMINAL_REPLACEMENTS):
  for from_, to_ in replacements:
    text = text.replace(from_, to_)
  return text


def _compile_and_print(source):
  """Compile an EBNF file and print the resulting source."""
  compiler = Compiler(source)
  print(compiler.output_source)
  # from .primitive import pprint
  # pprint(compiler.grammar)


if __name__ == "__main__":
  import sys

  if len(sys.argv) > 1:
    for filename in sys.argv[1:]:
      with open(filename, "r") as rf:
        source = rf.read()
      _compile_and_print(source)
  else:
    _compile_and_print(sys.stdin)
