
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="cp1252" />
    <title>Image Embedding</title>
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="next" title="Image Grid" href="imagegrid.html" />
    <link rel="prev" title="Image Viewer" href="imageviewer.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="imagegrid.html" title="Image Grid"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="imageviewer.html" title="Image Viewer"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Orange3 Image Analytics  documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <div class="section" id="image-embedding">
<h1>Image Embedding</h1>
<div class="figure align-default">
<img alt="../_images/image-embedding.png" src="../_images/image-embedding.png" />
</div>
<p>Image embedding through deep neural networks.</p>
<div class="section" id="signals">
<h2>Signals</h2>
<p><strong>Inputs</strong>:</p>
<ul>
<li><p><strong>Images</strong></p>
<p>List of images.</p>
</li>
</ul>
<p><strong>Outputs</strong>:</p>
<ul>
<li><p><strong>Embeddings</strong></p>
<p>Images represented with a vector of numbers.</p>
</li>
<li><p><strong>Skipped Images</strong></p>
<p>List of images where embeddings were not calculated.</p>
</li>
</ul>
</div>
<div class="section" id="description">
<h2>Description</h2>
<p><strong>Image Embedding</strong> reads images and uploads them to a remote server or evaluate them locally.
Deep learning models are used to calculate a feature vector for each image.
It returns an enhanced data table with additional columns (image descriptors).</p>
<p>Images can be imported with <a class="reference internal" href="importimages.html"><span class="doc">Import Images</span></a> widget or as paths to images in a spreadsheet.
In this case the column with images paths needs a three-row header with <em>type=image</em> label in the third row.</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/header-example.png"><img alt="../_images/header-example.png" src="../_images/header-example.png" style="width: 897.0px; height: 376.0px;" /></a>
</div>
<p>Image Embedding offers several embedders, each trained for a specific task.
Images are sent to a server or they are evaluated locally on the user’s computer, where vectors representations are computed.
SqueezeNet embedder offers a fast evaluation on users computer which does not require an internet connection.
If you decide to use other embedders than SqueezeNet, you will need an internet connection.
Images sent to the server are not stored anywhere.</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/ImageEmbedding-stamped.png"><img alt="../_images/ImageEmbedding-stamped.png" src="../_images/ImageEmbedding-stamped.png" style="width: 339.0px; height: 340.0px;" /></a>
</div>
<ol class="arabic">
<li><p>Information on the number of embedded images and images skipped.</p></li>
<li><p>Settings:</p>
<ul>
<li><p><em>Image attribute</em>: attribute containing images you wish to embed</p></li>
<li><p><em>Embedder</em>:</p>
<blockquote>
<div><ul class="simple">
<li><p>SqueezeNet: <a class="reference external" href="https://arxiv.org/abs/1602.07360" target="_blank">Small and fast</a> model for image recognition trained on ImageNet.</p></li>
<li><p>Inception v3: <a class="reference external" href="https://arxiv.org/abs/1512.00567" target="_blank">Google’s Inception v3</a>  model trained on ImageNet.</p></li>
<li><p>VGG-16: <a class="reference external" href="https://arxiv.org/abs/1409.1556" target="_blank">16-layer image recognition model</a> trained on ImageNet.</p></li>
<li><p>VGG-19: <a class="reference external" href="https://arxiv.org/abs/1409.1556" target="_blank">19-layer image recognition model</a> trained on ImageNet.</p></li>
<li><p>Painters: A model trained to <a class="reference external" href="http://blog.kaggle.com/2016/11/17/painter-by-numbers-competition-1st-place-winners-interview-nejc-ilenic/" target="_blank">predict painters from artwork images</a>.</p></li>
<li><p>DeepLoc: A model trained to analyze <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/29036616" target="_blank">yeast cell images</a>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
<li><p>Tick the box on the left to start the embedding automatically. Alternatively, click <em>Apply</em>. To cancel the embedding, click <em>Cancel</em>.</p></li>
<li><p>Access help.</p></li>
</ol>
</div>
<div class="section" id="example">
<h2>Example</h2>
<p>Let us first import images from a folder with <a class="reference internal" href="importimages.html"><span class="doc">Import Images</span></a>.
We have three images of an orange, a banana and a strawberry in a folder called Fruits.
From <strong>Import Images</strong> we will send a data table containing a column with image paths
to <strong>Image Embedding</strong>.</p>
<p>We will use the default embedder <em>SqueezeNet</em>.
The widget will automatically start retrieving image vectors from the server.</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/ImageEmbedding-Example1.png"><img alt="../_images/ImageEmbedding-Example1.png" src="../_images/ImageEmbedding-Example1.png" style="width: 585.5px; height: 434.5px;" /></a>
</div>
<p>Once the computation is done, you can observe the enhanced data in a <strong>Data Table</strong>.
With the retrived embeddings, you can continue with any machine learning method Orange offers. Below is an example for clustering.</p>
<div class="figure align-default">
<a class="reference internal image-reference" href="../_images/ImageEmbedding-Example2.png"><img alt="../_images/ImageEmbedding-Example2.png" src="../_images/ImageEmbedding-Example2.png" style="width: 1070.0px; height: 829.0px;" /></a>
</div>
</div>
</div>


          </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="imagegrid.html" title="Image Grid"
             >next</a> |</li>
        <li class="right" >
          <a href="imageviewer.html" title="Image Viewer"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Orange3 Image Analytics  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Laboratory of Bioinformatics, Faculty of Computer Science, University of Ljubljana.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.
    </div>
  </body>
</html>