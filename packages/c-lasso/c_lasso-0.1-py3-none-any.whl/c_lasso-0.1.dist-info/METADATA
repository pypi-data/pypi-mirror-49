Metadata-Version: 2.1
Name: c-lasso
Version: 0.1
Summary: Algorithms for constrained Lasso problems
Home-page: https://github.com/Leo-Simpson/CLasso
Author: Leo Simpson
Author-email: leo.bill.simpson@gmail.com
License: MIT
Platform: UNKNOWN

Constrained sparse regression functions in Python

To install the package : 
    pip install c_lasso

To import the package :
    import classo


1) Different type of problem : 
	- Least square :             min || Ax-y ||^2 + lambda * ||x||_1			
	- Huber  :                   min  h_rho(Ax-y) + lambda * ||x||_1	
	- Concomitant Least square : min || Ax-y ||^2/sigma + n*sigma + lambda * ||x||_1
	- Concomitant Huber :        min h_rho( (Ax-y)/sigma ) + n)*sigma + lambda * ||x||_1



2) Different methods for solving the problems : 

    Four main methods have been implemented for those.


        Forward Backward splitting method:
            Standard way to solve a convex minimisation problem with an addition of
            smooth and non-smooth function : Projected Proximal Gradient Descent. This
            method only works with the two non concomitants problems. For the huber
            problem, we use the second formulation.

        No-proj method
            Similar to the Projected Proximal Gradient Descent, but which does not involve
            a projection, which can be difficult to compute for some matrix C. Only for
            non concomitant problems.

        Double prox method
            Use of Doulgas Rachford splitting algorithm which use the proximal operator of
            both functions. It also solves concomitant problems, but it is usefull even in the
            non concomitant case because it is usually more efficient than forward backward
            splitting method. For the huber problem, we use the second formulation, then
            we change it into a Least square problem of dimension m (m + d) instead of m d.

        ODE method  
            From the KKT conditions, we can derive an simple ODE for the solution of
            the non concomitants problems, which shows that the solution is piecewise-
            affine. For the least square, as the problem can always be reported to a a non
            concomitant problem for another lambda, one can use the whole non-concomitant-
            path computed with the ODE method to then solve the concomitant-path.



3) Two main functions 

    For solving the problem for a fix \lambda : 

    fixlasso (matrix, lam, typ ='LS ', meth ='choose ', plot_time =True, plot_sol =True, plot_sigm =True, rho = 1.345)

         -matrix
            Matrices (A;C; y) of the problem.

         -lam
            Lambda/lambdamax in [0; 1] where lambdamax is a majoration of the lambda when the solution is null 
            (depends on the type of problem).

         -typ
            Type of problem : 'Huber', 'Concomitant' , 'Concomitant Huber' or 'LS'. 
            Any other string will set the type of problem to Least Square.

         -meth
            Method to solve the problem. If wrong input, the algorithm choose the method according to lambda
                - Possibilities for types 'LS' and 'Huber' : 'FB', 'Noproj', '2prox', 'ODE'.
                - Possibilities for type 'Concomitant' : '2prox', 'ODE'.
                - Possibilities for type 'Concomitant Huber' : '2prox'.

         -plot_time
            If set to True : prints the running time.

         -plot_sol
            If set to True : plots the solution in a bars diagram.

         -plot_sigm
            If set to True and the type we solve a concomitant problem : prints sigma/sigmamax.

         -rho
            Normalized rho for non-concomitant Huber problem : rho * sqrt(m) / norm_inf(y)
            Unormalized sigma for concomitant Huber problem.


         -returns
            The function returns : 
                An 'numpy.ndarray' type vector representing the solution betafor non concomitant problems, 
                A tuple containing beta and sigma for the concomitant problems.






    For solving the problem for the whole path :

    pathlasso (matrix, lambdas ='choose ', lamin =1e -2, typ='LS ', meth ='ODE ', plot_time =True, plot_sol =True, plot_sigm =True, rho = 1.345, compare = False )



        -matrix
            Matrices (A;C; y) of the problem.

        -lambdas
            Gives the list of lambda/lambdamax in [0; 1] where we need the problem to be solved. 
            If a boolean is given, it is the next parameter that will give the path.

        -lamin
            If lambdas is a boolean, it gives the lambda/lambdamax minimum : 
            the algorithm will solve the problem for all lambda in [lamin * lambdamax; lambdamax] 
            (with 100 points).	

        -typ
            Type of problem : 'Huber', 'Concomitant' , 'Concomitant Huber' or 'LS'. 
            Any other string will set the type of problem to Least Square.

        -meth
            Method to solve the problem. If wrong input, the algorithm choose the method according to lambda.
                - Possibilities for types 'LS' and 'Huber' : 'FB', 'Noproj', '2prox', 'ODE'.
                - Possibilities for type 'Concomitant' : '2prox', 'ODE'.
                - Possibilities for type 'Concomitant Huber' : '2prox'.

            For each case except 'ODE', the algorithm solves the problem for each lambda of the path using warm starts.


        -plot_time
            If set to True : prints the running time.

        -plot_sol
            If set to True : plots the solution in a bars diagram.

        -plot_sigm
            If set to True and the type we solve a concomitant problem : prints sigma/sigmamax.

        -rho
            Normalized rho for non-concomitant Huber problem : rho * sqrt(m) / norm_inf(y)
            Unormalized sigma for concomitant Huber problem.


        -returns
            The function returns :  
                a list 'numpy.ndarray' type vector representing the solution beta for each lambda ;
                the list of lambda corresponding (unormalized), 
                also the list of sigmas for the concomitant problems.





4) Little functions :

    For computing the theoretical lambda/lambdamax in the case of concomitant problems :  

        model_selection(m,d)

            Where m is the number of sample and d the number of parameter, it returns : lam0 = sqrt(2/m) invPhi(1-t), with invPhi the quantile function for the standard normal distribution, and t is the solution to the equation t*p = invPhi(1-t)**4 + 2*invPhi(1-t)**2



    For computing the solution using cross-validation and the previous main functions : 

        CV(matrices,k=5,typ='LS',test=0.4,lamin=1e-2, print_lam= True)

            Where k is the number of 'cluster' used, test is the proportion of sample kept for testing, and print lam tells us if the function also print the lambda/lambdamax used. The function returns the solution Beta as a 'numpy.ndarray'.












