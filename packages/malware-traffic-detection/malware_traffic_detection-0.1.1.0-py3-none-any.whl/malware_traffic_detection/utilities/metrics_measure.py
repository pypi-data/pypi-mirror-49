from collections import Counter, OrderedDict

from sklearn.metrics import confusion_matrix
import numpy as np


def confusion_matrix_local(y_pred, y_true):
    TP = 0.0
    FN = 0.0
    FP = 0.0
    TN = 0.0
    # print(f'y_pred={OrderedDict(Counter(y_pred))}, y_true={OrderedDict(Counter(y_true))}')
    for idx, (v1, v2) in enumerate(zip(y_pred, y_true)):
        if v1 == v2:
            if int(v1) == 0:
                TP += 1
            else:
                TN += 1
        else:  # v1 !=v2
            if int(v1) == 0:  # v1 ='0' (attack), v2 = '1' (normal)
                FP += 1
            else:  # v1 = '1' (normal), v2 = '0': (attack)
                FN += 1

    if TP + FN != 0.0:
        TPR = TP / (TP + FN)
    else:
        TPR = 0.0

    if FP + TN != 0.0:
        FPR = FP / (FP + TN)
    else:
        FPR = 0.0

    # print(f'[{TP}(TP)\t{FN}(FN)\n{FP}(FP)\t{TN}(TN)]')
    #
    # print(f'Tpr={TPR}, Fpr={FPR}')
    cm = np.asarray([TP, FN, FP, TN]).reshape(2, 2)

    return cm


def sklearn_confusion_matrix():
    y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]
    y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]
    cm = confusion_matrix(y_true, y_pred, labels=["ant", "bird", "cat"])
    print(cm)
    # array([[2, 0, 0],
    #        [0, 0, 1],
    #        [1, 0, 2]])

    tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()
    # >> > (tn, fp, fn, tp)
    # (0, 2, 1, 1)
    print(tn, fp, fn, tp)
    cm = [tn, fp, fn, tp]

    return cm


def mean_square_error(x1, x2, axis=1):
    # x1=np.asarray([[1,2,3],[4,5,6]])
    # x2 = np.asarray([[1, 2, 0], [1, 0, 2]])
    square_v = np.square(x1 - x2)  # by elementwise square
    # print(f'square_v={square_v}')
    cols = x1.shape[1]
    dist = np.sum(square_v, axis=axis) / cols  # axis = 1, add by column
    # print(f'dist={dist}')

    return dist


def torch_mse(x1, x2):
    from torch import nn
    import torch

    x1 = torch.Tensor(x1)
    x2 = torch.Tensor(x2)
    loss = nn.MSELoss(reduction='none')
    output = loss(x1, x2)
    print(output)
    loss = nn.MSELoss(reduction='elementwise_mean')
    output = loss(x1, x2)
    print(output)
    loss = nn.MSELoss(reduction='sum')
    # input = torch.randn(3, 5, requires_grad=True)
    # target = torch.randn(3, 5)
    output = loss(x1, x2)
    print(output)


def compare_mse():
    x1 = np.asarray([[1, 2, 3], [4, 5, 6]])
    x2 = np.asarray([[1, 2, 0], [1, 0, 2]])
    print(f'x1={x1}')
    print(f'x2={x2}')

    mean_square_error(x1, x2)
    torch_mse(x1, x2)


if __name__ == '__main__':
    compare_mse()
    # confusion_matrix()
